总结
● 寄存器：CPU提供的，读写ns级别，容量字节级别。
● CPU缓存：CPU和内存间的缓存，读写10ns级别，容量较大一些，百到千节。
● 主存：动态内存，读写100ns级别，容量GB级别。
● 外部存储介质：磁盘、SSD，读写ms级别，容量可扩展到TB级别。
地址空间是一个进程可用于寻址内存的一套地址的集合。每个进程都有一个自己的地址空间，并且这个地址空间独立于其它进程的地址空间。使用基址寄存器和界限器可以实现。
虚拟内存技术允许程序使用的内存大于计算机的实际内存
虚拟内存的基本思想是，每个进程有用独立的逻辑地址空间，内存被分为大小相等的多个块,称为页(Page).每个页都是一段连续的地址。对于进程来看,逻辑上貌似有很多内存空间，其中一部分对应物理内存上的一块(称为页框，通常页和页框大小相等)，还有一些没加载在内存中的对应在硬盘上。
处理器 8086 中，它可以寻址空间达到 1M，即地址线扩展到了 20 位，由于当时制造20位的寄存器比较困难，为了能在 16 位的寄存器的基础上寻址 20 位的地址空间，引入了一个重要的概念——段，8086 处理器为程序使用的代码段、数据段、堆栈段分别提供了专门的 16 位寄存器用于保存这些段的段基址
内存寻址过程分析
简单的说下逻辑地址、线性地址、物理地址的概念：
● 逻辑地址：程序代码中一个操作数或者一条指令的地址
● 线性地址：虚拟地址可映射 4G 内存空间（分页机制的产物，逻辑上连续）
● 物理地址：处理器的引脚发送到内存总线上的电信号相对应
逻辑地址由两部分组成：
● 段选择符: 16 位长的字段
● 段内偏移地址：32 位长的字段（最大的段大小为 4GB）
为了快速找到段选择符所指定的段的位置，处理器提供了段寄存器；因为段寄存器中存放的只是段选择符的地址，由段选择符来索引实际的段描述符还需要查找全局描述符表（GDT）和局部描述符表（LDT）中。同样 GDT 和 LDT 的地址也是存放在寄存器中的。为了加速逻辑地址到线性地址的转换过程，80x86提供了一种附加的非编程寄存器，即每当一个段选择符装入寄存器时，相对应的段描述符就由内存装入到这个非编程寄存器中。
分段机制下地址转换的过程
一个逻辑地址由段选择符和段内偏移组成，在转换成线性地址时，分段单元执行以下操作：
1. 先检查段选择符的 TI 字段，判断这个段的段描述符是存放在 GDT 中还是 LDT 中
2. 然后由段选择符中的 Index 索引到实际的段描述符将 Index 索引到实际的段描述符的地址✖️8，再加上 gdtr或者 ldtr 寄存器中的值。这个过程就完成了段起始的位置的计算
3. 最后把计算的结果加上逻辑地址中的段内偏移就得到了线性地址

80386开始支持存储器分页管理机制，分页机制是为了配合操作系统中的虚拟内存管理而引入的，分页机制目的是为了将线性地址转换成物理地址，如果不启用分页管理机制，那么线性地址就是物理地址。如何方便的管理这些置换或者加载的内容呢？操作系统引入了页的概念，页是一个存储单位，分页机制把线性地址空间和物理地址空间分别划分为大小相同的块，一般为4K 大小。
页、页框、页表的概念
● 页：对应着线性地址，线性地址被分成以固定大小为单位的组，称为页，页大小一般为4K
● 页框：对应着物理地址，物理地址也就是 RAM，被分成固定大小的页框，每个页框对应一个实际的页
● 页表：用来将页映射到具体的页框中的数据结构
线性地址的转换过程需要两步，首先是查找页目录找到具体的页表，然后查找页表，找到具体的页。如果这个页不存在 RAM 中，即缺页，还会引发缺页中断，申请调页；如果存在 RAM 就可以完成线性地址到具体物理地址的转换了。
分页机制中每个活动进程必须有一个页目录，不必为进程的所有页表都分配 RAM，只有实际使用到时才分配，这样才会更有效率，进程正在使用的页目录地址存放在 cr3 寄存器中。
当一个线性地址第一次使用时，通过慢速访问 RAM 中的页表计算出相应的物理地址，同时物理地址被存放到 TLB 的表项中，以便下次对同一个物理地址的引用可以快速的得到转换。在多处理器中，每个 CPU 都有自己的 TLB
虚拟内存和物理内存的匹配是通过页表实现；引入多级页表的原因是避免把全部页表一直存在内存中。页表的目的是把虚拟页面映射为页框
1） 使用多级页表可以使得页表在内存中离散存储。举个例子：比如虚拟地址空间大小为4G，每个页大小依然为4K，如果使用一级页表的话，共有2^20个页表项，如果每一个页表项占4B，那么存放所有页表项需要4M，为了能够随机访问，那么就需要连续4M的内存空间来存放所有的页表项
2） 使用多级页表可以节省页表内存 (在大多数情况都是进程的4GB虚拟地址空间都是没有使用的，实际使用的都是小于4GB的，所以我们说多级页表可以节省页表内存。)
那么为什么不分级的页表就做不到这样节约内存呢？我们从页表的性质来看，保存在主存中的页表承担的职责是将虚拟地址翻译成物理地址；假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有1M个页表项来映射，而二级页表则最少只需要1K个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。
每个进程一个页表，存放在内存，页表的起始地址放在进程的pcb中，当某进程运行时，将其页表的起始地址放在页表寄存器中。
在Unix系统中进程由三部分组成，分别是进程控制块(pcb)、程序段和数据段。Unix系统中把进程控制块分成proc结构和user结构两部分
假如目标内存页在物理内存中没有对应的页帧或者存在但无对应权限，CPU 就无法获取数据，这种情况下CPU就会报告一个缺页错误
● Hard Page Fault - 物理内存中没有对应的页帧
● Soft Page Fault - 物理内存中是存在对应页帧的，此时MMU只需要建立映射即可
● Invalid Page Fault - 无效缺页错误
page fault(缺页异常)分为三种情况：非法区域越界、合法区域权限不对、合法区域权限对
ZONE_NORMAL和DMA_ZONE合成ZONE_LOW；
因为有的DMA硬件只能访问内存条的低32M的地址，因此分出DMA_ZONE用于弥补DMA硬件缺陷
Buddy算法将内存条的空闲页放到一些列的链表中
slab的核心思想是以对象的观点来管理内存，slab 分配算法采用 cache 来存储内核对象
所谓共享内存，就是多个进程间共同地使用同一段物理内存空间，它是通过将同一段物理内存映射到不同进程的虚拟空间来实现的
fork()的实际开销就是复制父进程的一个页表和为子进程创建一个进程描述符，也就是说只有当进程空间中各段的内存内容发生变化时，父进程才将其内容复制一份传给子进程，大大提高了效率。
那么子进程的物理空间没有代码，怎么去取指令执行exec系统调用呢？
其实，在fork()之后，exec()之前，子进程和父进程是共享物理空间（内存区）的，子进程的代码段，数据段和堆栈都指向父进程物理空间，即两者的虚拟空间不同，但物理空间其实是同一个，当父进程或者子进程有需要修改段的行为时，再为子进程分配相应段的物理空间，若不是exec则内核会给子进程的数据段，堆栈段分配相应的物理空间，至此二者各自有各自的物理空间，互不影响。而代码段则继续共享父进程的物理空间，因为两者的代码完全相同，但如果是因为exec,，由于二者的执行的代码不同，则也需为子进程分配代码段的物理空间。
缓存（cache）与缓冲(buffer)的主要区别
Buffer的核心作用是用来缓冲，缓和冲击。比如你每秒要写100次硬盘，对系统冲击很大，浪费了大量时间在忙着处理开始写和结束写这两件事嘛。用个buffer暂存起来，变成每10秒写一次硬盘，对系统的冲击就很小，写入效率高了，日子过得爽了。极大缓和了冲击。
Cache的核心作用是加快取用的速度。比如你一个很复杂的计算做完了，下次还要用结果，就把结果放手边一个好拿的地方存着，下次不用再算了。加快了数据取用的速度。
简单来说就是buffer偏重于写，而cache偏重于读。
2. 堆栈哪个分配内存更快
堆是一个比堆栈复杂得多的数据结构。
对于许多体系结构，在堆栈上分配内存只是改变堆栈指针的问题，即它是一条指令。在堆上分配内存涉及查找足够大的块，拆分它，以及管理“簿记”，以便以不同的顺序允许free()之类的内容。
当范围（通常是函数）退出时，保证在堆栈上分配的内存被释放，并且不可能仅释放其中的一部分。
3. pagecache
文件 Cache 分为两个层面，一是 Page Cache，另一个 Buffer Cache，每一个 Page Cache 包含若干 Buffer Cache。内存管理系统和 VFS 只与 Page Cache 交互，内存管理系统负责维护每项 Page Cache 的分配和回收，同时在使用 memory map 方式访问时负责建立映射；VFS 负责 Page Cache 与用户空间的数据交换。而具体文件系统则一般只与 Buffer Cache 交互，它们负责在外围存储设备和 Buffer Cache 之间交换数据。Page Cache、Buffer Cache、文件以及磁盘之间的关系如图 2 所示，Page 结构和 buffer_head 数据结构的关系如图 3 所示。在上述两个图中，假定了 Page 的大小是 4K，磁盘块的大小是 1K。本文所讲述的，主要是指对 Page Cache 的管理。
应用发起的文件读写（系统调用read/write），先到VFS层，VFS层会根据file_operations获取具体文件系统的read/write的具体实现，一般的，具体文件系统会直接用系统默认的实现，即通过PageCache来完成文件读写。但是，如果PageCache不命中，最终还是需要具体文件系统来进行page读写。
当我们发起一个read(fd, buffer, count)时，VFS将将其进一步转换成file->f_ops->read(file, buffer, count, &file->f_pos)，即，将其交给具体文件系统来处理，具体文件系统可以直接根据pos，buffer，count来到介质上读文件内容，但是，显然，我们应该有一个缓存来处理了，PageCache是VFS层提供了一个缓存，所有具体文件系统可以直接使用它，而不需要实现自己的一套缓存逻辑。使用PageCache的方法很简单，在创建文件时，将file->f_ops->read设置成generic_file_read。
VFS就是Virtual File System虚拟文件系统，这是Linux文件系统对外的接口
page cache和buffer cache最大的差别在于：page cache是对文件数据的缓存；buffer cache是对设备(磁盘)数据的缓存。两者在实现上差别不是很大，都是采用radix树进行管理。
一般来说内存占用大小有如下规律：VSS >= RSS >= PSS >= USS














1. 扫盲篇
1.1 操作系统存储层次
常见的计算机存储层次如下：
● 寄存器：CPU提供的，读写ns级别，容量字节级别。
● CPU缓存：CPU和CPU间的缓存，读写10ns级别，容量较大一些，百到千节。
● 主存：动态内存，读写100ns级别，容量GB级别。
● 外部存储介质：磁盘、SSD，读写ms级别，容量可扩展到TB级别。
CPU内的缓存示意图如下：
其中 L1d 和 L1i 都是CPU内部的cache，
● L1d 是数据cache。
● L1i 是指令缓存。
● L2是CPU内部的，不区分指令和数据的。
● 由于现代PC有多个CPU，L3缓存多个核心共用一个。
对于编程人员来说，绝大部分观察主存和外部存储介质就可以了。如果要做极致的性能优化，可以关注L1、L2、L3的cache，比如nginx的绑核操作、pthread调度会影响CPU cache等。

1.2 基本概念
为什么要有地址空间？
首先直接把物理地址暴露给进程会带来严重问题
1. 如果用户程序可以寻址内存的每个字节，就有很大的可能破坏操作系统，造成系统崩溃
2. 同时运行多个程序十分困难 地址空间创造了一个新的内存抽象，地址空间是一个进程可用于寻址内存的一套地址的集合。每个进程都有一个自己的地址空间，并且这个地址空间独立于其它进程的地址空间。使用基址寄存器和界限器可以实现。

虚拟内存技术允许程序使用的内存大于计算机的实际内存
虚拟内存的基本思想是，每个进程有用独立的逻辑地址空间，内存被分为大小相等的多个块,称为页(Page).每个页都是一段连续的地址。对于进程来看,逻辑上貌似有很多内存空间，其中一部分对应物理内存上的一块(称为页框，通常页和页框大小相等)，还有一些没加载在内存中的对应在硬盘上。
内存寻址过程分析
简单的介绍了一下操作系统内存寻址的发展历程，接下来细致的分析一下分段和分页机制内存寻址的过程。首先先简单的说下逻辑地址、线性地址、物理地址的概念：
● 逻辑地址：程序代码中一个操作数或者一条指令的地址
● 线性地址：虚拟地址可映射 4G 内存空间（分页机制的产物，逻辑上连续）
● 物理地址：处理器的引脚发送到内存总线上的电信号相对应

1.2.1 分段机制详解
代码中使用到的逻辑地址由两部分组成：
● 段选择符: 16 位长的字段
● 段内偏移地址：32 位长的字段（最大的段大小为 4GB）
为了快速找到段选择符所指定的段的位置，处理器提供了段寄存器（cs、ss、ds、es、fs、gs），相比于 8086 来说，80386 新增了 fs、gs 附加段寄存器，主要是为了减少 es 这个寄存器的负担引入的。
值得注意的是 cs 寄存器，它含有一个 2 位的字段，用以指定当前 CPU 的特权等级 DPL(规定访问该段的权限级别(Descriptor Privilege Level)，每个段的DPL固定)，3 为用户态，0 为内核态。
段描述符
前面说到段选择符是一个 16 位的字段，格式如下：
● 15 ~ 3 位：Index 索引号
● 2 位：TI 标志，指明段描述符在 GDT（TI=0）中或者 LDT（TI=1）中
● 1 ~ 0 位：RPL(说明的是进程对段访问的请求权限(Request Privilege Level)) 标志，请求者的特权级
由段选择符中的索引号可以索引到段的信息，段的信息是由8字节的段描述符表示，段描述符存放在全局描述符表（GDT）和局部描述符表（LDT）中。同样 GDT 和 LDT 的地址也是存放在寄存器中的，通常系统初始化的时候会初始化 gdtr 控制寄存器，写入 GDT 表的地址，如果每个进程除了存放 GDT 外，还需要自己的附加的段，就可以创建一个 LDT，将 LDT 表的地址写进 ldtr 寄存器中。
快速访问段描述符
因为段寄存器中存放的只是段选择符的地址，由段选择符来索引实际的段描述符还需要查找 GDT 或者 LDT 表。为了加速逻辑地址到线性地址的转换过程，80x86提供了一种附加的非编程寄存器，即每当一个段选择符装入寄存器时，相对应的段描述符就由内存装入到这个非编程寄存器中。
这样当针对那个段的逻辑地址转换线性地址时，就不用访问 GDT 或者 LDT 表，直接引用存放这个段描述符的非编程寄存器就好了。
分段机制下地址转换的过程
一个逻辑地址由段选择符和段内偏移组成，在转换成线性地址时，分段单元执行以下操作：
1. 先检查段选择符的 TI 字段，判断这个段的段描述符是存放在 GDT 中还是 LDT 中
2. 然后由段选择符中的 Index 索引到实际的段描述符将 Index 索引到实际的段描述符的地址✖️8，再加上 gdtr或者 ldtr 寄存器中的值。这个过程就完成了段起始的位置的计算
3. 最后把计算的结果加上逻辑地址中的段内偏移就得到了线性地址

1.2.2 分页机制详解
前面提到分页机制是为了配合操作系统中的虚拟内存管理而引入的，分页机制目的是为了将线性地址转换成物理地址。
基本概念
简要讲述一下页、页框、页表的概念
● 页：对应着线性地址，线性地址被分成以固定大小为单位的组，称为页，页大小一般为4K
● 页框：对应着物理地址，物理地址也就是 RAM，被分成固定大小的页框，每个页框对应一个实际的页
● 页表：用来将页映射到具体的页框中的数据结构
常规分页
因为每个页的大小为 4KB，为了映射 4GB 的物理空间，页表中将会有 1MB（2^20） 的映射项，对应每个程序来都要保存一个这么大的页表项是难以接受的，所以引出了多级页表的概念，也称为 页目录。
也就是说线性地址的转换过程需要两步，首先是查找页目录找到具体的页表，然后查找页表，找到具体的页。如果这个页不存在 RAM 中，即缺页，还会引发缺页中断，申请调页；如果存在 RAM 就可以完成线性地址到具体物理地址的转换了。
分页机制中每个活动进程必须有一个页目录，不必为进程的所有页表都分配 RAM，只有实际使用到时才分配，这样才会更有效率，进程正在使用的页目录地址存放在 cr3 寄存器中。

内存寻址过程，程序中使用的逻辑地址到最后的物理地址的转换过程：
1	逻辑地址 -->(分段机制)  线性地址  -->(分页机制) 物理地址
转换后援缓冲器 TLB
除了内部的硬件高速缓存外，还包含了一个转换后援缓冲器 TLB 的高速缓存用以加快线性地址的转换。当一个线性地址第一次使用时，通过慢速访问 RAM 中的页表计算出相应的物理地址，同时物理地址被存放到 TLB 的表项中，以便下次对同一个物理地址的引用可以快速的得到转换。
在多处理器中，每个 CPU 都有自己的 TLB。当 CPU 的 cr3 寄存器被修改时，那么 TLB 的所有项都变得无效了，因为当前使用的是新的页目录了。

而虚拟内存和物理内存的匹配是通过页表实现，页表存在MMU中，页表中每个项通常为32位，既4byte，除了存储虚拟地址和页框地址之外，还会存储一些标志位，比如是否缺页，是否修改过，写保护等。可以把MMU想象成一个接收虚拟地址项返回物理地址的方法。
因为页表中每个条目是4字节，现在的32位操作系统虚拟地址空间会是2的32次方，即使每页分为4K，也需要2的20次方 * 4字节 = 4M的空间，为每个进程建立一个4M的页表并不明智。因此在页表的概念上进行推广，产生二级页表，二级页表每个对应4M的虚拟地址，而一级页表去索引这些二级页表，因此32位的系统需要1024个二级页表，虽然页表条目没有减少，但内存中可以仅仅存放需要使用的二级页表和一级页表，大大减少了内存的使用。
（1）使用多级页表可以使得页表在内存中离散存储。多级页表实际上是增加了索引，有了索引就可以定位到具体的项。举个例子：比如虚拟地址空间大小为4G，每个页大小依然为4K，如果使用一级页表的话，共有2^20个页表项，如果每一个页表项占4B，那么存放所有页表项需要4M，为了能够随机访问，那么就需要连续4M的内存空间来存放所有的页表项。随着虚拟地址空间的增大，存放页表所需要的连续空间也会增大，在操作系统内存紧张或者内存碎片较多时，这无疑会带来额外的开销。但是如果使用多级页表，我们可以使用一页来存放页目录项，页表项存放在内存中的其他位置，不用保证页目录项和页表项连续。
（2）使用多级页表可以节省页表内存。使用一级页表，需要连续的内存空间来存放所有的页表项。多级页表通过只为进程实际使用的那些虚拟地址内存区请求页表来减少内存使用量（出自《深入理解Linux内核》第三版51页）。举个例子：一个进程的虚拟地址空间是4GB，假如进程只使用4MB内存空间。对于一级页表，我们需要4M空间来存放这4GB虚拟地址空间对应的页表，然后可以找到进程真正使用的4M内存空间。也就是说，虽然进程实际上只使用了4MB的内存空间，但是为了访问它们我们需要为所有的虚拟地址空间建立页表。但是如果使用二级页表的话，一个页目录项可以定位4M内存空间，存放一个页目录项占4K，还需要一页用于存放进程使用的4M（4M=1024*4K，也就是用1024个页表项可以映射4M内存空间）内存空间对应的页表，总共需要4K（页表）+4K（页目录）=8K来存放进程使用的这4M内存空间对应页表和页目录项，这比使用一级页表节省了很多内存空间。当然，在这种情况下，使用多级页表确实是可以节省内存的。但是，我们需要注意另一种情况，如果进程的虚拟地址空间是4GB，而进程真正使用的内存也是4GB，如果是使用一级页表，则只需要4MB连续的内存空间存放页表，我们就可以寻址这4GB内存空间。而如果使用的是二级页表的话，我们需要4MB内存存放页表，还需要4KB内存来存放页目录项，此时多级页表反倒是多占用了内存空间。注意在大多数情况都是进程的4GB虚拟地址空间都是没有使用的，实际使用的都是小于4GB的，所以我们说多级页表可以节省页表内存。
引入多级页表的原因是避免把全部页表一直存在内存中。
虚拟地址和物理地址匹配规则
虚拟页号可用做页表的索引，以找到该虚拟页面对应页表项。由页表项可以找到页框号。然后把页框号拼接到偏移量的高位端，以替换虚拟页号，形成送往内存的物理地址。
页表的目的是把虚拟页面映射为页框，从数学的角度来说，页表是一个函数，它的参数是，虚拟页号，结果是物理页框号。通过这个函数可以把虚拟地址中的虚拟页面域替换为页框域，从而形成物理地址。

me: 在分页存储管理方式中，是每个进程都有自己的页表，还是所有进程使用一个页表呢？
如果每个进程都有自己的页表的话，页表寄存器怎么放的下这么多页表始址。
如果所有进程只用一个页表的话，那么两个不同进程的相同逻辑地址，地址转换后得到的物理地址就相同了呀。进程的逻辑地址空间就不独立了。
teacher:每个进程一个页表，存放在内存，页表的起始地址放在进程的pcb中，当某进程运行时，将其页表的起始地址放在页表寄存器中。单CPU系统中只能有一个进程处于执行状态，因此一个页表寄存器可供系统中所有的进程交替使用。

在Unix系统中进程由三部分组成，分别是进程控制块(pcb)、程序段和数据段。Unix系统中把进程控制块分成proc结构和user结构两部分
找到该行后根据是否命中及权限取出物理地址，如果没有命中引发page fault给虚拟地址分配物理内存，如果没有权限，会引发segv。
page fault(缺页异常)分为三种情况：非法区域、合法区域权限不对、合法区域权限对

ZONE_NORMAL和DMA_ZONE合成ZONE_LOW；
因为有的DMA硬件只能访问内存条的低32M的地址，因此分出DMA_ZONE用于弥补DMA硬件缺陷，如果DMA硬件可访问的内存条足够大，则不需要DMA_ZONE，这时内存条只分为ZONE_HIGH和ZONE_LOW

1.2.3 buddy算法
Buddy算法将内存条的空闲页放到一些列的链表中，这些链表分别存放连续空闲1页、连续空闲2页、连续空闲24页、连续空闲28页、连续空闲216页、连续空闲232页内存等
伙伴系统从物理连续的大小固定的段上进行分配。从这个段上分配内存，采用 2 的幂分配器来满足请求分配单元的大小为 2 的幂（4KB、 8KB、16KB 等）。请求单元的大小如不适当，就圆整到下一个更大的 2 的幂。例如，如果请求大小为 11KB，则按 16KB 的段来请求。

让我们考虑一个简单例子。假设内存段的大小最初为 256KB，内核请求 21KB 的内存。最初，这个段分为两个伙伴，称为 AL 和 AR，每个的大小都为 128KB；这两个伙伴之一进一步分成两个 64KB 的伙伴，即 BL 和 BR。然而，从 21KB 开始的下一个大的 2 的幂是 32KB，因此 BL 或 BR 再次划分为两个 32KB 的伙伴 CL 和 CR。因此，其中一个 32KB 的段可用于满足 21KB 请求。这种方案如图 1 所示，其中 CL 段是分配给 21KB 请求的。

图 1 伙伴系统分配

伙伴系统的一个优点是：通过称为合并的技术，可以将相邻伙伴快速组合以形成更大分段。例如，在图 1 中，当内核释放已被分配的 CL 时，系统可以将 CL 和 CR 合并成 64KB 的段。段 BL 继而可以与伙伴 BR 合并，以形成 128KB 段。最终，可以得到原来的 256KB 段。

伙伴系统的明显缺点是：由于圆整到下一个 2 的幂，很可能造成分配段内的碎片。例如，33KB 的内存请求只能使用 64KB 段来满足。事实上，我们不能保证因内部碎片而浪费的单元一定少于 50%。
1.2.4 slab分配
slab的核心思想是以对象的观点来管理内存
分配内核内存的第二种策略称为slab分配。每个 slab 由一个或多个物理连续的页面组成，每个 cache 由一个或多个 slab 组成，每个内核数据结构都有一个 cache。

例如，用于表示进程描述符、文件对象、信号量等的数据结构都有各自单独的 cache。每个 cache 含有内核数据结构的对象实例（称为 object）。例如，信号量 cache 有信号量对象，进程描述符 cache 有进程描述符对象，等等。

图 2 slab 分配

图 2 显示了 slab、cache 及 object 三者之间的关系。该图显示了 2 个大小为 3KB 的内核对象和 3 个大小为 7KB 的对象，它们位于各自的 cache 中。
slab 分配算法采用 cache 来存储内核对象。在创建 cache 时，若干起初标记为 free 的对象被分配到 cache。cache 内的对象数量取决于相关 slab 的大小。例如，12KB slab（由 3 个连续的 4KB 页面组成）可以存储 6 个 2KB 对象。最初，cache 内的所有对象都标记为空闲。当需要内核数据结构的新对象时，分配器可以从 cache 上分配任何空闲对象以便满足请求。从 cache 上分配的对象标记为 used（使用）。
让我们考虑一个场景，这里内核为表示进程描述符的对象从 slab 分配器请求内存。在 Linux 系统中，进程描述符属于 struct task_struct 类型，它需要大约 1.7KB 的内存。当 Linux 内核创建一个新任务时，它从 cache 中请求 struct task_struct 对象的必要内存。cache 利用已经在 slab 中分配的并且标记为 free (空闲）的 struct task_struct 对象来满足请求。
在 Linux 中，slab 可以处于三种可能状态之一：
1. 满的：slab 的所有对象标记为使用。
2. 空的：slab 上的所有对象标记为空闲。
3. 部分：slab 上的对象有的标记为使用，有的标记为空闲。
slab 分配器首先尝试在部分为空的 slab 中用空闲对象来满足请求。如果不存在，则从空的 slab 中分配空闲对象。如果没有空的 slab 可用，则从连续物理页面分配新的 slab，并将其分配给 cache；从这个 slab 上，再分配对象内存。
slab 分配器提供两个主要优点：
1. 没有因碎片而引起内存浪费。碎片不是问题，因为每个内核数据结构都有关联的 cache，每个 cache 都由一个或多个 slab 组成，而 slab 按所表示对象的大小来分块。因此，当内核请求对象内存时，slab 分配器可以返回刚好表示对象的所需内存。
2. 可以快速满足内存请求。因此，当对象频繁地被分配和释放时，如来自内核请求的情况，slab 分配方案在管理内存时特别有效。分配和释放内存的动作可能是一个耗时过程。然而，由于对象已预先创建，因此可以从 cache 中快速分配。再者，当内核用完对象并释放它时，它被标记为空闲并返回到 cache，从而立即可用于后续的内核请求。
slab 分配器首先出现在 Solaris 2.4 内核中。由于通用性质，Solaris 现在也将这种分配器用于某些用户模式的内存请求。最初，Linux 使用的是伙伴系统；然而，从版本 2.2 开始，Linux 内核采用 slab 分配器。
现在，最近发布的 Linux 也包括另外两个内核内存分配器，SLOB 和 SLUB 分配器（Linux 将 slab 实现称为 SLAB）。
简单块列表（SLOB）分配器用于有限内存的系统，例如嵌入式系统。SLOB 工作采用 3 个对象列表：小（用于小于 256 字节的对象）、中（用于小于 1024 字节的对象）和大（用于小于页面大小的对象）。内存请求采用首先适应策略，从适当大小的列表上分配对象。
从版本 2.6.24 开始，SLUB 分配器取代 SLAB，成为 Linux 内核的默认分配器。SLUB 通过减少 SLAB 分配器所需的大量开销，来解决 slab 分配的性能问题，一个改变是，在 SLAB 分配下每个 slab 存储的元数据，移到 Linux 内核用于每个页面的结构 page。此外，对于 SLAB 分配器，每个 CPU 都有队列以维护每个 cache 内的对象，SLUB 会删除这些队列。
对于具有大量处理器的系统，分配给这些队列的内存量是很重要的。因此，随着系统处理器数量的增加，SLUB 性能也更好。

1.2.5 共享内存
共享内存是进程间通信中最简单的方式之一。共享内存允许两个或更多进程访问同一块内存，就如同 malloc() 函数向不同进程返回了指向同一个物理内存区域的指针。当一个进程改变了这块地址中的内容的时候，其它进程都会察觉到这个。其实所谓共享内存，就是多个进程间共同地使用同一段物理内存空间，它是通过将同一段物理内存映射到不同进程的虚拟空间来实现的。由于映射到不同进程的虚拟空间中，不同进程可以直接使用，不需要像消息队列那样进行复制，所以共享内存的效率很高。共享内存可以通过mmap()映射普通文件机制来实现，也可以System V共享内存机制来实现，System V是通过映射特殊文件系统shm中的文件实现进程间的共享内存通信，也就是说每个共享内存区域对应特殊文件系统shm中的一个文件。

1.2.6 vss、rss、pss、uss
一般来说内存占用大小有如下规律：VSS >= RSS >= PSS >= USS
1. VSS - Virtual Set Size （用处不大）
虚拟耗用内存（包含共享库占用的全部内存，以及分配但未使用内存）。其大小还包括了可能不在RAM中的内存（比如虽然malloc分配了空间，但尚未写入）。VSS 很少被用于判断一个进程的真实内存使用量。

2. RSS - Resident Set Size （用处不大
 实际使用物理内存（包含共享库占用的全部内存）。但是RSS还是可能会造成误导，因为它仅仅表示该进程所使用的所有共享库的大小，它不管有多少个进程使用该共享库，该共享库仅被加载到内存一次。所以RSS并不能准确反映单进程的内存占用情况

3. PSS - Proportional Set Size （仅供参考）
 实际使用的物理内存（比例分配共享库占用的内存，按照进程数等比例划分）。例如：如果有三个进程都使用了一个共享库，共占用了30页内存。那么PSS将认为每个进程分别占用该共享库10页的大小。 PSS是非常有用的数据，因为系统中所有进程的PSS都相加的话，就刚好反映了系统中的   总共占用的内存。 而当一个进程被销毁之后， 其占用的共享库那部分比例的PSS，将会再次按比例分配给余下使用该库的进程。这样PSS可能会造成一点的误导，因为当一个进程被销毁后， PSS不能准确地表示返回给全局系统的内存。

4. USS - Unique Set Size （非常有用）
 进程独自占用的物理内存（不包含共享库占用的内存）。USS是非常非常有用的数据，因为它反映了运行一个特定进程真实的边际成本（增量成本）。当一个进程被销毁后，USS是真实返回给系统的内存。当进程中存在一个可疑的内存泄露时，USS是最佳观察数据。


1.2.7 fork
fork()的实际开销就是复制父进程的一个页表和为子进程创建一个进程描述符，也就是说只有当进程空间中各段的内存内容发生变化时，父进程才将其内容复制一份传给子进程，大大提高了效率。
那么子进程的物理空间没有代码，怎么去取指令执行exec系统调用呢？
其实，在fork()之后，exec()之前，子进程和父进程是共享物理空间（内存区）的，子进程的代码段，数据段和堆栈都指向父进程物理空间，即两者的虚拟空间不同，但物理空间其实是同一个，当父进程或者子进程有需要修改段的行为时，再为子进程分配相应段的物理空间，若不是exec则内核会给子进程的数据段，堆栈段分配相应的物理空间，至此二者各自有各自的物理空间，互不影响。而代码段则继续共享父进程的物理空间，因为两者的代码完全相同，但如果是因为exec,，由于二者的执行的代码不同，则也需为子进程分配代码段的物理空间。

1.2.8 cache & buffer
缓存（cache）与缓冲(buffer)的主要区别
Buffer的核心作用是用来缓冲，缓和冲击。比如你每秒要写100次硬盘，对系统冲击很大，浪费了大量时间在忙着处理开始写和结束写这两件事嘛。用个buffer暂存起来，变成每10秒写一次硬盘，对系统的冲击就很小，写入效率高了，日子过得爽了。极大缓和了冲击。
Cache的核心作用是加快取用的速度。比如你一个很复杂的计算做完了，下次还要用结果，就把结果放手边一个好拿的地方存着，下次不用再算了。加快了数据取用的速度。
简单来说就是buffer偏重于写，而cache偏重于读。
 
ps：有时候大家要好好理解这些专有名词字面上的意思，对理解这些概念有好处，缓冲：缓解冲击，缓存：临时存储

缓冲区的作用：
1.可以解除两者的制约关系，数据可以直接送往缓冲区，高速设备不用再等待低速设备，提高了计算机的效率。例如：我们使用打印机打印文档，由于打印机的打印速度相对较慢，我们先把文档输出到打印机相应的缓冲区，打印机再自行逐步打印，这时我们的CPU可以处理别的事情。
2.可以减少数据的读写次数，如果每次数据只传输一点数据，就需要传送很多次，这样会浪费很多时间，因为开始读写与终止读写所需要的时间很长，如果将数据送往缓冲区，待缓冲区满后再进行传送会大大减少读写次数，这样就可以节省很多时间。例如：我们想将数据写入到磁盘中，不是立马将数据写到磁盘中，而是先输入缓冲区中，当缓冲区满了以后，再将数据写入到磁盘中，这样就可以减少磁盘的读写次数，不然磁盘很容易坏掉。
简单来说，缓冲区就是一块内存区，它用在输入输出设备和CPU之间，用来存储数据。它使得低速的输入输出设备和高速的CPU能够协调工作，避免低速的输入输出设备占用CPU，解放出CPU，使其能够高效率工作。

total：系统总内存大小（分物理内存mem、交换分区swap）
used：已使用的内存（total - free - buffers - cache）
free：未使用的内存
shared：通常情况下是tmpfs（内存文件系统）使用的内存
buffers：内核缓冲区使用的内存
cache：page cache和slab所占用的内存之和
buff/cache：buffers + cache
available：在不进行swap的前提下还有多少内存可用于创建新的进程。这个跟free、buff/cache字段中的数字有所不同，这里的剩余内存是free加上可以被回收（有些slab、cache正在使用，不能回收）的page cache、mem slab的值的总和。

2. 堆栈哪个分配内存更快
栈内存更快，栈是和代码段一同被载入到CPU内存中的，用C写得程序在被编译成机器指令之后，同一个函数栈上的变量会被保存在寄存器中的，并且栈上的内存基本上都是在编译的时候就确定了得，由于CPU的运算原理明显依赖寄存器的，所以栈上的内存访问速度明显比堆上快，现在CPU的设计一、二级缓存的大小已经最后栈内存的使用，所以效率明显要高很多，而堆上的内存由于和函数栈不在同一个地址段，所以堆上的内存很有可能不在寄存器或者CUP缓存中，访问命中率就低，同时效率也就会低很多，因为要出发好多系统内核调用，内存需要从硬盘到内存到CUP缓存再到寄存器。
栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。
堆则是C/C++函数库提供的，它的机制是很复杂的，例如为了分配一块内存，库函数会按照一定的算法（具体的算法可以参考数据结构/操作系统）在堆内存中搜索可用的足够大小的空间，如果没有足够大小的空间（可能是由于内存碎片太多），就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会分到足够大小的内存，然后进行返回。显然，堆的效率比栈要低得多。

3. pagecache
文件 Cache 分为两个层面，一是 Page Cache，另一个 Buffer Cache，每一个 Page Cache 包含若干 Buffer Cache。内存管理系统和 VFS 只与 Page Cache 交互，内存管理系统负责维护每项 Page Cache 的分配和回收，同时在使用 memory map 方式访问时负责建立映射；VFS 负责 Page Cache 与用户空间的数据交换。而具体文件系统则一般只与 Buffer Cache 交互，它们负责在外围存储设备和 Buffer Cache 之间交换数据。Page Cache、Buffer Cache、文件以及磁盘之间的关系如图 2 所示，Page 结构和 buffer_head 数据结构的关系如图 3 所示。在上述两个图中，假定了 Page 的大小是 4K，磁盘块的大小是 1K。本文所讲述的，主要是指对 Page Cache 的管理。
应用发起的文件读写（系统调用read/write），先到VFS层，VFS层会根据file_operations获取具体文件系统的read/write的具体实现，一般的，具体文件系统会直接用系统默认的实现，即通过PageCache来完成文件读写。但是，如果PageCache不命中，最终还是需要具体文件系统来进行page读写。
当我们发起一个read(fd, buffer, count)时，VFS将将其进一步转换成file->f_ops->read(file, buffer, count, &file->f_pos)，即，将其交给具体文件系统来处理，具体文件系统可以直接根据pos，buffer，count来到介质上读文件内容，但是，显然，我们应该有一个缓存来处理了，PageCache是VFS层提供了一个缓存，所有具体文件系统可以直接使用它，而不需要实现自己的一套缓存逻辑。使用PageCache的方法很简单，在创建文件时，将file->f_ops->read设置成generic_file_read。